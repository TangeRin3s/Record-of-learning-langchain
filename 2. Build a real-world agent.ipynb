{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d429fd11",
   "metadata": {},
   "source": [
    "### Define the system prompt\n",
    "\n",
    "The system prompt defines your agent’s role and behavior. Keep it specific and actionable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f23026",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b4834",
   "metadata": {},
   "source": [
    "### Create tools\n",
    "\n",
    "**Tools** let a model interact with external systems by calling functions you define. <br>\n",
    "Tools can depend on **runtime context** and also interact with **agent memory**.<br>\n",
    "Notice below how the ```python get_user_location``` tool uses runtime context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "# dataclass\n",
    "# Python 标准库\n",
    "# 用来快速定义只包含数据的类\n",
    "# 自动生成 __init__, __repr__ 等方法\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "# ToolRuntime\n",
    "# LangChain 中的 运行时容器\n",
    "# 用来在 tool 执行时：\n",
    "# 访问上下文（context）\n",
    "# 访问当前会话信息、用户信息等\n",
    "\n",
    "# 这里用的是：\n",
    "# runtime: ToolRuntime[Context]\n",
    "\n",
    "# 意味着：\n",
    "# 这个 Tool 不从 LLM 输入参数中拿数据\n",
    "# 而是 从系统运行时上下文中拿数据\n",
    "\n",
    "# get_user_location 并不是由模型主动获取用户 ID，而是 LangChain 在执行工具时，通过 ToolRuntime 将预先绑定的运行时上下文（Context）注入到工具函数中。\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4deb93",
   "metadata": {},
   "source": [
    "**ToolRuntime 是什么？**\n",
    "\n",
    "ToolRuntime[Context] 包含什么？\n",
    "```text\n",
    "runtime\n",
    " ├── context   ← 你定义的 Context 实例\n",
    " ├── metadata\n",
    " ├── config\n",
    " └── other runtime info\n",
    "```\n",
    "\n",
    "你这里用到了：\n",
    "```python\n",
    "runtime.context.user_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1f978",
   "metadata": {},
   "source": [
    "### Configure your model\n",
    "\n",
    "Set up your **language model** with the right parameters for your use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07192531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-4o\",\n",
    "    # temperature 控制模型“敢不敢随机”\n",
    "    # 低 → 更保守、更确定、更像“考试答案”\n",
    "    # 高 → 更发散、更有创造性、更像“头脑风暴”\n",
    "    temperature=0.5,\n",
    "    timeout=10,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1983a0",
   "metadata": {},
   "source": [
    "### Define response format\n",
    "\n",
    "Optionally, define a structured response format if you need the agent responses to match a specific schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54041792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    # | 部分            | 含义          |\n",
    "    # | ------------- | ----------- |\n",
    "    # | `str \\| None` | 要么是字符串，要么是空 |\n",
    "    # | `= None`      | 默认值是 None   |\n",
    "    # | 是否必填          | ❌ 否         |\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c50ba",
   "metadata": {},
   "source": [
    "### Add memory\n",
    "\n",
    "Add **memory** to your agent to maintain state across interactions. This allows the agent to remember previous conversations and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80e47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc8592",
   "metadata": {},
   "source": [
    "### Create and run the agent\n",
    "\n",
    "Now assemble your agent with all the components and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response=\"Looks like the sun is in a committed relationship with Florida today! It's sunny and bright, so don't forget your shades.\", weather_conditions='Sunny')\n",
      "ResponseFormat(punny_response=\"No problem, I'm always here to weather any question you have!\", weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    # 作用：\n",
    "    # 让 Agent “记住自己上一次对话执行到哪”\n",
    "    # 它和下面的 thread_id 配合使用。\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# 它是在给 agent.invoke(..., config=config) 传一个运行配置，其中最重要的是：\n",
    "# thread_id = 用来标识“这一条对话线程/会话”的唯一 ID。\n",
    "# 你可以把它理解成：同一条聊天的会话编号。\n",
    "\n",
    "# 为什么需要 thread_id？\n",
    "# 因为你启用了：\n",
    "\n",
    "# checkpointer=checkpointer   # 例如 InMemorySaver()\n",
    "\n",
    "# 有了 checkpointer 之后，框架会在每次调用 agent 时：\n",
    "# 用 thread_id 去 checkpointer 里查有没有旧的检查点（checkpoint / state）\n",
    "# 如果有：恢复上次的 state（包括执行进度、历史消息等，取决于实现）\n",
    "# 执行本轮\n",
    "# 把更新后的 state 再保存回 thread_id 对应的槽位\n",
    "\n",
    "# 所以：\n",
    "# thread_id 就是 “checkpoint 的 key”。\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
